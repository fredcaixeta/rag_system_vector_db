# scripts/collection_analyzer.py
import os
from dotenv import load_dotenv
from milvus_db import ZillizClient
import pandas as pd
from collections import Counter
import matplotlib.pyplot as plt

# Carregar vari√°veis de ambiente
load_dotenv()

class CollectionAnalyzer:
    def __init__(self, collection_name="dr_voss_v2"):
        self.client = ZillizClient(
            api_key=os.getenv("ZILLIZ_API_KEY"),
            cluster_id=os.getenv("ZILLIZ_CLUSTER_ID"),
            region=os.getenv("ZILLIZ_REGION", "gcp-us-west1")
        )
        self.collection_name = collection_name
    
    def get_collection_stats(self):
        """Obt√©m estat√≠sticas b√°sicas da cole√ß√£o"""
        stats = self.client.get_collection_stats(self.collection_name)
        print("\nüìä Estat√≠sticas da Cole√ß√£o:")
        print(f"Nome: {self.collection_name}")
        print(f"Total de Documentos: {stats['data']['entityCount']}")
        print(f"Dimens√£o dos Vetores: {stats['data']['dimension']}")
        print(f"M√©trica de Similaridade: {stats['data']['metricType']}")
        return stats
    
    def analyze_text_data(self, sample_size=100):
        """Analisa os dados textuais da cole√ß√£o"""
        print("\nüîç Analisando dados textuais...")
        data = self.client.get_all_entities(self.collection_name)
        
        if not data:
            print("Nenhum dado encontrado na cole√ß√£o.")
            return None
        
        # Criar DataFrame para an√°lise
        df = pd.DataFrame(data)
        
        # Estat√≠sticas b√°sicas
        print(f"\nüìù Estat√≠sticas Textuais (amostra de {len(df)} documentos):")
        print(f"Comprimento m√©dio do texto: {df['text'].str.len().mean():.0f} caracteres")
        print(f"Comprimento m√≠nimo: {df['text'].str.len().min()} caracteres")
        print(f"Comprimento m√°ximo: {df['text'].str.len().max()} caracteres")
        
        # Distribui√ß√£o por p√°gina (se existir o campo)
        if 'page' in df.columns:
            page_dist = Counter(df['page'])
            print("\nüìñ Distribui√ß√£o por P√°gina:")
            for page, count in sorted(page_dist.items()):
                print(f"P√°gina {page}: {count} documentos")
            
            # Plotar distribui√ß√£o
            plt.figure(figsize=(10, 5))
            df['page'].value_counts().sort_index().plot(kind='bar')
            plt.title('Documentos por P√°gina')
            plt.xlabel('N√∫mero da P√°gina')
            plt.ylabel('Quantidade de Documentos')
            plt.tight_layout()
            plt.savefig('page_distribution.png')
            print("\nüìà Gr√°fico salvo como 'page_distribution.png'")
        
        return df
    
    def analyze_vectors(self, sample_size=10):
        """Analisa os vetores de embedding"""
        print("\nüßÆ Analisando vetores de embedding...")
        data = self.client.query_entities(self.collection_name, limit=sample_size)
        
        if not data.get('data'):
            print("Nenhum dado encontrado na cole√ß√£o.")
            return None
        
        vectors = [item['vector'] for item in data['data']]
        
        print("\nüî¢ Estat√≠sticas dos Vetores (amostra):")
        print(f"Dimens√£o: {len(vectors[0])} (esperado: 384)")
        print(f"Valor m√≠nimo: {min(min(v) for v in vectors):.4f}")
        print(f"Valor m√°ximo: {max(max(v) for v in vectors):.4f}")
        print(f"Valor m√©dio: {sum(sum(v) for v in vectors)/(sample_size*len(vectors[0])):.4f}")
        
        return vectors
    
    def full_analysis(self):
        """Executa an√°lise completa"""
        print(f"\nüî¨ Iniciando an√°lise da cole√ß√£o '{self.collection_name}'")
        self.get_collection_stats()
        df = self.analyze_text_data()
        vectors = self.analyze_vectors()
        
        print("\n‚úÖ An√°lise conclu√≠da!")
        return {
            "stats": self.client.get_collection_stats(self.collection_name),
            "text_samples": df.head(3).to_dict('records') if df is not None else None,
            "vector_samples": vectors[:2] if vectors is not None else None
        }

if __name__ == "__main__":
    analyzer = CollectionAnalyzer()
    analysis_results = analyzer.full_analysis()
    
    # Salvar resultados em JSON
    import json
    with open('collection_analysis.json', 'w') as f:
        json.dump(analysis_results, f, indent=2)
    print("\nüìÑ Resultados salvos em 'collection_analysis.json'")