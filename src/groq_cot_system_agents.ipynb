{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f049c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import os\n",
    "from typing import List, Dict\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "GROQ_API_KEY = os.getenv('groq_key')\n",
    "\n",
    "FILE_PATH = r'C:\\Users\\fuedj\\Documents\\Code\\RAG_Dr_Voss\\llm-case-study-main\\src\\parte1_another.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95843c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt(file_path: str) -> str:\n",
    "    \"\"\"Carrega o conteúdo do arquivo de texto\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 800) -> List[str]:\n",
    "    \"\"\"Divide o texto em chunks\"\"\"\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5003705",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = load_txt(FILE_PATH)\n",
    "\n",
    "\n",
    "chunks = chunk_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f521003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1432"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eefd58f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77dfdc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_large_chunk(chunk: str, max_size: int = 8000) -> list[str]:\n",
    "    parts = []\n",
    "    while len(chunk) > max_size:\n",
    "        cut_index = chunk.rfind('.', 0, max_size)\n",
    "        if cut_index == -1:\n",
    "            cut_index = chunk.rfind(' ', 0, max_size)\n",
    "        if cut_index == -1:\n",
    "            cut_index = max_size  # Não achou ponto nem espaço, corta bruto\n",
    "        parts.append(chunk[:cut_index+1].strip())\n",
    "        chunk = chunk[cut_index+1:].strip()\n",
    "    if chunk:\n",
    "        parts.append(chunk)\n",
    "    return parts\n",
    "\n",
    "def chunk_diary_by_day_and_paragraph(diary_text: str) -> list[str]:\n",
    "    chunks = []\n",
    "    current_day_content = \"\"\n",
    "    date_pattern = r\"(\\d{1,2})(?:st|nd|rd|th)? Day of ([A-Za-z]+) (18\\d{2}) - ([A-Za-z\\s]+)\"\n",
    "\n",
    "    for line in diary_text.splitlines():\n",
    "        if re.match(date_pattern, line):\n",
    "            # Encontrou um novo dia\n",
    "            if current_day_content:\n",
    "                # Divida o conteúdo do dia anterior por parágrafos (linhas não vazias)\n",
    "                paragraphs = [p.strip() for p in current_day_content.strip().split('\\n\\n') if p.strip()]\n",
    "                chunks.extend(paragraphs)\n",
    "            current_day_content = line + \"\\n\"  # Comece o conteúdo do novo dia\n",
    "        else:\n",
    "            current_day_content += line + \"\\n\"\n",
    "\n",
    "    # Processar o conteúdo do último dia\n",
    "    if current_day_content:\n",
    "        paragraphs = [p.strip() for p in current_day_content.strip().split('\\n\\n') if p.strip()]\n",
    "        for paragraph in paragraphs:\n",
    "            if len(paragraph) > 800:\n",
    "                chunks.extend(split_large_chunk(paragraph))\n",
    "            else:\n",
    "                chunks.append(paragraph)\n",
    "    \n",
    "    return [chunk for chunk in chunks if chunk] # Remove empty ones \n",
    "\n",
    "list_chunk = chunk_diary_by_day_and_paragraph(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0437da23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = list_chunk\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c9a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert Agent Response: {'analysis': {'narrative_elements': {'locations': ['capital city of Veridia', 'Assembly House'], 'interactions': ['Observation of cultural artifacts (sculptures, paintings)', 'Attending legislative debate on sustainability initiatives'], 'methods': ['Journal entries', 'Documentation of public policy discussions', 'Visual documentation of art and architecture']}, 'regional_insights': {'veridia': [\"Cultural emphasis on arts under Queen Isolde's patronage\", 'Strong legislative focus on sustainability (80% renewable energy by 2050)', 'Blend of historical heritage with forward-thinking governance'], 'eldoria': []}}, 'metadata': {'relevance_score': 0.9, 'confidence': 0.85, 'contains_key_insight': True}}\n",
      "Expert Agent Response: {'analysis': {'narrative_elements': {'locations': ['Veridia (Takron Valley)', 'Eldoria'], 'interactions': [\"Engagement with a storyteller recounting Eldoria's Autumn festival\", \"Observation of Takron Valley's natural and labor environments\"], 'methods': ['Written journal entries', 'Sensory observation (sounds, scents, textures)', 'Storytelling as a source of cultural documentation']}, 'regional_insights': {'veridia': [\"Veridia's Takron Valley is depicted as a place of natural mist and labor, with pickaxes suggesting mining or quarry work.\", \"The valley's air is described as fresh and moist, contrasting with Eldoria's musty peat scents, highlighting environmental distinctiveness.\"], 'eldoria': [\"Eldoria's cultural vibrancy is conveyed through its Autumn festival, emphasizing athletic prowess and communal enthusiasm.\", \"The Celestium music symbolizes Eldoria's artistic identity and its enduring influence beyond physical presence, linking it to other regions.\"]}}, 'metadata': {'relevance_score': 0.85, 'confidence': 0.9, 'contains_key_insight': True}}\n",
      "Expert Agent Response: {'analysis': {'narrative_elements': {'locations': ['Valley (implied to be Veridia)', 'Cragstone Arch'], 'interactions': ['Conversations with miners', 'Storytelling with Bram', 'Participation in local customs (e.g., drinking ale)'], 'methods': ['Observation of labor practices', 'Oral history collection', 'Personal reflection on folklore']}, 'regional_insights': {'veridia': ['A community defined by labor and resilience, yet deeply tied to mystical folklore', 'A culture that blends practicality with belief in spiritual forces tied to the land', 'Echoes of the past (literal and metaphorical) shape daily life and identity'], 'eldoria': []}}, 'metadata': {'relevance_score': 0.85, 'confidence': 0.7, 'contains_key_insight': True}}\n",
      "Expert Agent Response: {'analysis': {'narrative_elements': {'locations': ['Veridia', 'Takron Valley', 'Eldoria'], 'interactions': ['Joining locals in consuming Zelphar stew', 'Engaging with miners in Takron Valley discussing Bluefire Opal', \"Observing Eldoria's javelin throwing contest traditions\"], 'methods': ['Journal entries with dated reflections', 'Sensory documentation (taste, visual descriptions)', 'Interviews/observations of local labor and traditions']}, 'regional_insights': {'veridia': ['Cultural emphasis on communal meals and traditional cuisine', 'Economic reliance on mining and natural resources like Bluefire Opal', 'Community bonded through labor and shared heritage'], 'eldoria': ['Celebration of physical prowess through javelin contests', 'Annual festivals as central to cultural identity', 'Traditions that unite the community annually']}}, 'metadata': {'relevance_score': 0.9, 'confidence': 0.8, 'contains_key_insight': True}}\n",
      "Expert Agent Response: {'analysis': {'narrative_elements': {'locations': ['Elderwood', 'Takron Valley', \"Takron's Veil\"], 'interactions': ['Engaging with storytellers about Olwen and the Heron of Eldoria', \"Observing miners' cultural practices in Takron Valley\", 'Reflecting on musical contrasts between regions'], 'methods': ['Journaling with dated entries', 'Oral history collection', 'Cultural observation', 'Comparative analysis of traditions']}, 'regional_insights': {'veridia': [\"Cultural resilience in rugged environments, as seen in the miners' traditions\", 'Contrast between somber landscapes and rich communal practices', \"Connection to the author's personal heritage through festival music\"], 'eldoria': ['Veneration of athletic prowess and legendary figures like the Heron', 'Oral storytelling as a communal narrative tradition', 'Festivals blending competition (javelin contests) with communal celebration']}}, 'metadata': {'relevance_score': 0.85, 'confidence': 0.75, 'contains_key_insight': True}}\n",
      "Central Agent:\n",
      "{  \"comparative_analysis\": {\n",
      "    \"documentation_methods\": {\n",
      "      \"veridia\": [\n",
      "        \"Journal entries\",\n",
      "        \"Documentation of public policy discussions\",\n",
      "        \"Visual documentation of art and architecture\",\n",
      "        \"Observation of labor practices\",\n",
      "        \"Sensory observation (sounds, scents, textures)\",\n",
      "        \"Interviews/observations of local labor and traditions\",\n",
      "        \"Oral history collection\",\n",
      "        \"Personal reflection on folklore\"\n",
      "      ],\n",
      "      \"eldoria\": [\n",
      "        \"Storytelling as a source of cultural documentation\",\n",
      "        \"Sensory observation (musty peat scents, music)\",\n",
      "        \"Participation in festivals and traditions\",\n",
      "        \"Oral history collection\",\n",
      "        \"Observation of athletic competitions (javelin contests)\",\n",
      "        \"Cultural observation of communal celebrations\"\n",
      "      ],\n",
      "      \"shared\": [\n",
      "        \"Journal entries\",\n",
      "        \"Oral history collection\",\n",
      "        \"Sensory documentation\",\n",
      "        \"Observation of communal practices\"\n",
      "      ]\n",
      "    },\n",
      "    \"cultural_insights\": {\n",
      "      \"veridia\": [\n",
      "        \"Blend of artistic patronage (Queen Isolde) with legislative sustainability goals (80% renewable energy by 2050)\",\n",
      "        \"Cultural duality of rugged labor (mining, Takron Valley) and mystical folklore\",\n",
      "        \"Communal identity forged through shared heritage, food (Zelphar stew), and labor practices\",\n",
      "        \"Resilience in harsh environments paired with rich oral traditions\"\n",
      "      ],\n",
      "      \"eldoria\": [\n",
      "        \"Cultural emphasis on athletic prowess (javelin contests) and communal festivals\",\n",
      "        \"Artistic legacy symbolized by Celestium music persisting beyond physical presence\",\n",
      "        \"Oral storytelling (e.g., Olwen and the Heron) as a core identity mechanism\",\n",
      "        \"Environmental distinctiveness (musty peat scents) tied to cultural practices\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"narrative_arc\": {\n",
      "    \"key_events\": [\n",
      "      \"Attendance at Veridia's legislative debates on sustainability\",\n",
      "      \"Participation in Takron Valley's mining labor and folklore storytelling\",\n",
      "      \"Observation of Eldoria's Autumn festival and javelin contests\",\n",
      "      \"Engagement with both regions' culinary traditions (Zelphar stew, ale)\",\n",
      "      \"Reflections on musical and mythological connections between regions\"\n",
      "    ],\n",
      "    \"character_development\": [\n",
      "      \"Shift from surface-level documentation to deeper understanding of interplay between labor, art, and governance\",\n",
      "      \"Growing awareness of how environmental conditions shape cultural expressions\",\n",
      "      \"Recognition of shared heritage elements between Veridia and Eldoria through folklore and music\"\n",
      "    ]\n",
      "  },\n",
      "  \"unanswered_questions\": [\n",
      "    \"How do Veridia's sustainability policies reconcile with its labor-intensive mining practices?\",\n",
      "    \"What historical events led to Eldoria's veneration of athletic traditions over other cultural forms?\",\n",
      "    \"What unresolved tensions exist between Veridia's legislative goals and local labor communities?\",\n",
      "    \"How does the author's personal heritage influence their interpretation of regional identities?\",\n",
      "    \"What long-term impacts might Eldoria's oral traditions have on preserving or evolving their cultural identity?\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "=== Resposta Consolidada ===\n",
      "{\n",
      "  \"comparative_analysis\": {\n",
      "    \"documentation_methods\": {\n",
      "      \"veridia\": [\n",
      "        \"Journal entries\",\n",
      "        \"Documentation of public policy discussions\",\n",
      "        \"Visual documentation of art and architecture\",\n",
      "        \"Observation of labor practices\",\n",
      "        \"Sensory observation (sounds, scents, textures)\",\n",
      "        \"Interviews/observations of local labor and traditions\",\n",
      "        \"Oral history collection\",\n",
      "        \"Personal reflection on folklore\"\n",
      "      ],\n",
      "      \"eldoria\": [\n",
      "        \"Storytelling as a source of cultural documentation\",\n",
      "        \"Sensory observation (musty peat scents, music)\",\n",
      "        \"Participation in festivals and traditions\",\n",
      "        \"Oral history collection\",\n",
      "        \"Observation of athletic competitions (javelin contests)\",\n",
      "        \"Cultural observation of communal celebrations\"\n",
      "      ],\n",
      "      \"shared\": [\n",
      "        \"Journal entries\",\n",
      "        \"Oral history collection\",\n",
      "        \"Sensory documentation\",\n",
      "        \"Observation of communal practices\"\n",
      "      ]\n",
      "    },\n",
      "    \"cultural_insights\": {\n",
      "      \"veridia\": [\n",
      "        \"Blend of artistic patronage (Queen Isolde) with legislative sustainability goals (80% renewable energy by 2050)\",\n",
      "        \"Cultural duality of rugged labor (mining, Takron Valley) and mystical folklore\",\n",
      "        \"Communal identity forged through shared heritage, food (Zelphar stew), and labor practices\",\n",
      "        \"Resilience in harsh environments paired with rich oral traditions\"\n",
      "      ],\n",
      "      \"eldoria\": [\n",
      "        \"Cultural emphasis on athletic prowess (javelin contests) and communal festivals\",\n",
      "        \"Artistic legacy symbolized by Celestium music persisting beyond physical presence\",\n",
      "        \"Oral storytelling (e.g., Olwen and the Heron) as a core identity mechanism\",\n",
      "        \"Environmental distinctiveness (musty peat scents) tied to cultural practices\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"narrative_arc\": {\n",
      "    \"key_events\": [\n",
      "      \"Attendance at Veridia's legislative debates on sustainability\",\n",
      "      \"Participation in Takron Valley's mining labor and folklore storytelling\",\n",
      "      \"Observation of Eldoria's Autumn festival and javelin contests\",\n",
      "      \"Engagement with both regions' culinary traditions (Zelphar stew, ale)\",\n",
      "      \"Reflections on musical and mythological connections between regions\"\n",
      "    ],\n",
      "    \"character_development\": [\n",
      "      \"Shift from surface-level documentation to deeper understanding of interplay between labor, art, and governance\",\n",
      "      \"Growing awareness of how environmental conditions shape cultural expressions\",\n",
      "      \"Recognition of shared heritage elements between Veridia and Eldoria through folklore and music\"\n",
      "    ]\n",
      "  },\n",
      "  \"unanswered_questions\": [\n",
      "    \"How do Veridia's sustainability policies reconcile with its labor-intensive mining practices?\",\n",
      "    \"What historical events led to Eldoria's veneration of athletic traditions over other cultural forms?\",\n",
      "    \"What unresolved tensions exist between Veridia's legislative goals and local labor communities?\",\n",
      "    \"How does the author's personal heritage influence their interpretation of regional identities?\",\n",
      "    \"What long-term impacts might Eldoria's oral traditions have on preserving or evolving their cultural identity?\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import json\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "class AgentSystem:\n",
    "    def __init__(self, api_key: str, question: str):\n",
    "        self.api_key = api_key\n",
    "        self.partial_answers = []\n",
    "        self.session = None\n",
    "        self.question = question\n",
    "\n",
    "    async def __aenter__(self):\n",
    "        self.session = aiohttp.ClientSession()\n",
    "        return self\n",
    "\n",
    "    async def __aexit__(self, *args):\n",
    "        await self.session.close()\n",
    "\n",
    "    async def expert_agent(self, chunk: str) -> Optional[Dict]:\n",
    "        \"\"\"Agente especializado em análise narrativa\"\"\"\n",
    "        prompt = f\"\"\"Analyze this text excerpt regarding:\n",
    "        {self.question}\n",
    "\n",
    "        Return a VALID JSON with these REQUIRED fields:\n",
    "        {{\n",
    "            \"analysis\": {{\n",
    "                \"narrative_elements\": {{\n",
    "                    \"locations\": list[str],\n",
    "                    \"interactions\": list[str],\n",
    "                    \"methods\": list[str]\n",
    "                }},\n",
    "                \"regional_insights\": {{\n",
    "                    \"veridia\": list[str],\n",
    "                    \"eldoria\": list[str]\n",
    "                }}\n",
    "            }},\n",
    "            \"metadata\": {{\n",
    "                \"relevance_score\": float (0-1),\n",
    "                \"confidence\": float (0-1),\n",
    "                \"contains_key_insight\": bool\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        Text excerpt:\n",
    "        {chunk[:1500]}\"\"\"\n",
    "\n",
    "        try:\n",
    "            async with self.session.post(\n",
    "                \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n",
    "                json={\n",
    "                    \"model\": \"qwen-qwq-32b\",\n",
    "                    \"messages\": [{\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are a professional literary analyst. Return valid JSON.\"\n",
    "                    }, {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }],\n",
    "                    \"temperature\": 0.3,\n",
    "                    \"response_format\": {\"type\": \"json_object\"}\n",
    "                },\n",
    "                timeout=20\n",
    "            ) as response:\n",
    "                data = await response.json()\n",
    "                result = json.loads(data['choices'][0]['message']['content'])\n",
    "                \n",
    "                print(f\"Expert Agent Response: {result}\")\n",
    "                \n",
    "                # Verificação robusta da estrutura\n",
    "                if all(key in result for key in ['analysis', 'metadata']):\n",
    "                    if result['metadata'].get('relevance_score', 0) > 0.4:  # Threshold ajustável\n",
    "                        self.partial_answers.append(result)\n",
    "                        return result\n",
    "                return None\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON Error in chunk analysis: {str(e)}\")\n",
    "            return None\n",
    "        except KeyError as e:\n",
    "            print(f\"Missing key in response: {str(e)}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Expert agent error: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    async def central_agent(self) -> Dict:\n",
    "        \"\"\"Agente de síntese comparativa\"\"\"\n",
    "        context = \"\\n\".join(\n",
    "            f\"Chunk {i}:\\n{json.dumps(ans, indent=2)}\" \n",
    "            for i, ans in enumerate(self.partial_answers)\n",
    "        )\n",
    "\n",
    "        prompt = f\"\"\"Synthesize this analysis about:\n",
    "        {self.question}\n",
    "\n",
    "        Partial Analyses:\n",
    "        {context}\n",
    "\n",
    "        Return JSON with:\n",
    "        - comparative_analysis: {{\n",
    "            documentation_methods: {{\n",
    "                veridia: list[str],\n",
    "                eldoria: list[str],\n",
    "                shared: list[str]\n",
    "            }},\n",
    "            cultural_insights: {{\n",
    "                veridia: list[str],\n",
    "                eldoria: list[str]\n",
    "            }}\n",
    "          }}\n",
    "        - narrative_arc: {{\n",
    "            key_events: list[str],\n",
    "            character_development: list[str]\n",
    "          }}\n",
    "        - unanswered_questions: list[str]\"\"\"\n",
    "\n",
    "        try:\n",
    "            async with self.session.post(\n",
    "                \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n",
    "                json={\n",
    "                    \"model\": \"qwen-qwq-32b\",\n",
    "                    \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"response_format\": {\"type\": \"json_object\"}\n",
    "                },\n",
    "                timeout=20\n",
    "            ) as response:\n",
    "                data = await response.json()\n",
    "                \n",
    "                print(f\"Central Agent:\")\n",
    "                print(data['choices'][0]['message']['content'])\n",
    "                \n",
    "                return json.loads(data['choices'][0]['message']['content'])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Central agent error: {str(e)}\")\n",
    "            return {\"status\": \"consolidation_error\"}\n",
    "        \n",
    "    async def deep_analysis_agent(self, chunk: str):\n",
    "        \"\"\"Agente para análise qualitativa aprofundada\"\"\"\n",
    "        prompt = f\"\"\"Perform deep qualitative analysis of this text regarding:\n",
    "        {self.question}\n",
    "        \n",
    "        Focus on:\n",
    "        - Narrative devices used\n",
    "        - Cultural significance\n",
    "        - Author's perspective shifts\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            async with self.session.post(\n",
    "                \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n",
    "                json={\n",
    "                    \"model\": \"qwen-qwq-32b\",  # Modelo mais capaz para síntese\n",
    "                    \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"response_format\": {\"type\": \"json_object\"}\n",
    "                },\n",
    "                timeout=20\n",
    "            ) as response:\n",
    "                data = await response.json()\n",
    "                return json.loads(data['choices'][0]['message']['content'])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Central agent error: {str(e)}\")\n",
    "            return {\"status\": \"consolidation_error\"}\n",
    "\n",
    "async def analyze_document(api_key: str, question: str, chunks: List[str]) -> Tuple[Dict, List[Dict]]:\n",
    "    \"\"\"Processa o documento completo e retorna resposta consolidada + informações parciais\"\"\"\n",
    "    async with AgentSystem(api_key, question=question) as system:\n",
    "        # Primeira passada - Análise básica\n",
    "        tasks = [system.expert_agent(chunk) for chunk in chunks]\n",
    "        await asyncio.gather(*tasks)\n",
    "        \n",
    "        # # Segunda passada - Análise aprofundada nos chunks relevantes\n",
    "        # deep_analysis_tasks = [\n",
    "        #     system.deep_analysis_agent(chunk) \n",
    "        #     for chunk in chunks\n",
    "        # ]\n",
    "        # await asyncio.gather(*deep_analysis_tasks)\n",
    "        \n",
    "        return await system.central_agent()\n",
    "\n",
    "# Exemplo de uso:\n",
    "async def main():\n",
    "    question = \"\"\"\n",
    "    \n",
    "    Analyze the author's journey through Veridia and Eldoria, detailing the methods they employ\n",
    "    to document their experiences, and discuss how their interactions with people\n",
    "    and places shape their understanding of these regions' unique identities.\n",
    "    \"\"\"\n",
    "    \n",
    "    document_chunks = chunks  # Seus chunks aqui\n",
    "    \n",
    "    final_answer = await analyze_document(GROQ_API_KEY, question, document_chunks[:5])  # Teste com 5 chunks\n",
    "    \n",
    "    print(\"\\n=== Resposta Consolidada ===\")\n",
    "    print(json.dumps(final_answer, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    # print(\"\\n=== Informações Parciais ===\")\n",
    "    # for i, partial in enumerate(partials, 1):\n",
    "    #     print(f\"\\nFonte {i}:\")\n",
    "    #     print(json.dumps(partial, indent=2))\n",
    "\n",
    "# Para executar no Jupyter:\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83ca9425",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ee1423d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70a35f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experto Agent Decision: {'analysis': {'key_findings': [\"The author documents experiences through sensory descriptions (e.g., Zelphar stew's taste, Bluefire Opal's visual appeal) and participatory engagement with local customs.\", \"Interactions with locals (e.g., sharing meals, observing miners, attending traditions) reveal Veridia's cultural warmth and Eldoria's reverence for natural resources and communal events.\", \"The author's journey highlights regional identities through contrasts: Veridia's focus on communal comfort and Eldoria's celebration of physical skill and natural wonders (implied by the javelin contest and Bluefire Opal mining).\", \"Documentation methods include firsthand participation, observational notes on labor (miners' work) and cultural practices (festivals/contests), and sensory immersion in local cuisine.\"], 'missing_info': [\"Incomplete mention of Eldoria's event ('a...' cut off) limits understanding of its cultural significance.\", 'No explicit mention of tools/methods beyond sensory notes (e.g., journals, maps, interviews).', \"Lack of historical or political context for Veridia/Eldoria's development of these traditions and resources.\"]}, 'metadata': {'chunk_id': 1, 'relevance': 0.9, 'needs_more_context': True}}\n",
      "Experto Agent Decision: {'analysis': {'key_findings': [\"The author employs observational notes and institutional visits (e.g., the Assembly House) to document Veridia's cultural and political landscape.\", \"Veridia's identity is framed by its blend of artistic patronage (Queen Isolde's legacy) and progressive policy goals (80% renewable energy by 2050).\", \"Interactions with legislative processes (e.g., the Assembly of Voices debate) highlight the region's prioritization of sustainability as a core value.\", 'The author emphasizes institutional and historical markers (sculptures, paintings, legislative goals) to understand regional identity, suggesting a focus on structural and cultural frameworks.'], 'missing_info': ['No mention of Eldoria, as the text only describes Veridia.', 'Lack of detail on methods beyond observation (e.g., interviews, archival research).', \"Incomplete discussion of how interpersonal interactions (with locals, experts) shape the author's understanding.\", \"The text cuts off mid-sentence, leaving unresolved context about the debate's implications or the author's evolving perspective.\"]}, 'metadata': {'chunk_id': 0, 'relevance': 0.8, 'needs_more_context': True}}\n",
      "Experto Agent Decision: {'analysis': {'key_findings': [\"The author relies on secondhand accounts (e.g., storytellers) and sensory descriptions (e.g., music, scents) to document experiences, even when physically absent from locations like Eldoria's festival.\", 'Contrasts between environments (e.g., Takron Valley\\'s mist vs. Eldoria\\'s \"musty peat scents\") highlight distinct regional identities through sensory and atmospheric details.', \"Cultural elements like Eldoria's Celestium music and festival traditions are portrayed as threads in a shared cultural tapestry, suggesting interconnectedness between Veridia and Eldoria despite physical separation.\"], 'missing_info': [\"No explicit mention of direct interactions with people in Veridia beyond the storyteller; focus remains on the author's internal reflections.\", 'Methods of documentation beyond note-taking (e.g., sketches, interviews) are unmentioned.', \"The significance of Takron Valley's pickaxes and stone (implied labor or industry) to Veridia's identity is unresolved due to the text's abrupt cutoff.\"]}, 'metadata': {'chunk_id': 2, 'relevance': 0.7, 'needs_more_context': True}}\n",
      "Central Agent Decision: {'status': 'incomplete', 'answer': None, 'requested_chunks': [0, 1, 2], 'confidence': 0.9}\n",
      "Central Agent Decision: {'status': 'incomplete', 'answer': None, 'requested_chunks': [0, 1, 2], 'confidence': 0.6}\n",
      "Central Agent Decision: {'status': 'incomplete', 'answer': None, 'requested_chunks': [0, 1, 2], 'confidence': 0.6}\n",
      "\n",
      "=== Resultado Final ===\n",
      "{\n",
      "  \"status\": \"partial\",\n",
      "  \"answers\": [\n",
      "    {\n",
      "      \"analysis\": {\n",
      "        \"key_findings\": [\n",
      "          \"The author documents experiences through sensory descriptions (e.g., Zelphar stew's taste, Bluefire Opal's visual appeal) and participatory engagement with local customs.\",\n",
      "          \"Interactions with locals (e.g., sharing meals, observing miners, attending traditions) reveal Veridia's cultural warmth and Eldoria's reverence for natural resources and communal events.\",\n",
      "          \"The author's journey highlights regional identities through contrasts: Veridia's focus on communal comfort and Eldoria's celebration of physical skill and natural wonders (implied by the javelin contest and Bluefire Opal mining).\",\n",
      "          \"Documentation methods include firsthand participation, observational notes on labor (miners' work) and cultural practices (festivals/contests), and sensory immersion in local cuisine.\"\n",
      "        ],\n",
      "        \"missing_info\": [\n",
      "          \"Incomplete mention of Eldoria's event ('a...' cut off) limits understanding of its cultural significance.\",\n",
      "          \"No explicit mention of tools/methods beyond sensory notes (e.g., journals, maps, interviews).\",\n",
      "          \"Lack of historical or political context for Veridia/Eldoria's development of these traditions and resources.\"\n",
      "        ]\n",
      "      },\n",
      "      \"metadata\": {\n",
      "        \"chunk_id\": 1,\n",
      "        \"relevance\": 0.9,\n",
      "        \"needs_more_context\": true\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"analysis\": {\n",
      "        \"key_findings\": [\n",
      "          \"The author employs observational notes and institutional visits (e.g., the Assembly House) to document Veridia's cultural and political landscape.\",\n",
      "          \"Veridia's identity is framed by its blend of artistic patronage (Queen Isolde's legacy) and progressive policy goals (80% renewable energy by 2050).\",\n",
      "          \"Interactions with legislative processes (e.g., the Assembly of Voices debate) highlight the region's prioritization of sustainability as a core value.\",\n",
      "          \"The author emphasizes institutional and historical markers (sculptures, paintings, legislative goals) to understand regional identity, suggesting a focus on structural and cultural frameworks.\"\n",
      "        ],\n",
      "        \"missing_info\": [\n",
      "          \"No mention of Eldoria, as the text only describes Veridia.\",\n",
      "          \"Lack of detail on methods beyond observation (e.g., interviews, archival research).\",\n",
      "          \"Incomplete discussion of how interpersonal interactions (with locals, experts) shape the author's understanding.\",\n",
      "          \"The text cuts off mid-sentence, leaving unresolved context about the debate's implications or the author's evolving perspective.\"\n",
      "        ]\n",
      "      },\n",
      "      \"metadata\": {\n",
      "        \"chunk_id\": 0,\n",
      "        \"relevance\": 0.8,\n",
      "        \"needs_more_context\": true\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"analysis\": {\n",
      "        \"key_findings\": [\n",
      "          \"The author relies on secondhand accounts (e.g., storytellers) and sensory descriptions (e.g., music, scents) to document experiences, even when physically absent from locations like Eldoria's festival.\",\n",
      "          \"Contrasts between environments (e.g., Takron Valley's mist vs. Eldoria's \\\"musty peat scents\\\") highlight distinct regional identities through sensory and atmospheric details.\",\n",
      "          \"Cultural elements like Eldoria's Celestium music and festival traditions are portrayed as threads in a shared cultural tapestry, suggesting interconnectedness between Veridia and Eldoria despite physical separation.\"\n",
      "        ],\n",
      "        \"missing_info\": [\n",
      "          \"No explicit mention of direct interactions with people in Veridia beyond the storyteller; focus remains on the author's internal reflections.\",\n",
      "          \"Methods of documentation beyond note-taking (e.g., sketches, interviews) are unmentioned.\",\n",
      "          \"The significance of Takron Valley's pickaxes and stone (implied labor or industry) to Veridia's identity is unresolved due to the text's abrupt cutoff.\"\n",
      "        ]\n",
      "      },\n",
      "      \"metadata\": {\n",
      "        \"chunk_id\": 2,\n",
      "        \"relevance\": 0.7,\n",
      "        \"needs_more_context\": true\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"message\": \"Using partial results after central agent failure\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import json\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "class SmartAgentSystem:\n",
    "    def __init__(self, api_key: str, question: str, all_chunks: List[str]):\n",
    "        self.api_key = api_key\n",
    "        self.question = question\n",
    "        self.all_chunks = all_chunks\n",
    "        self.processed_chunks = set()\n",
    "        self.partial_answers = []\n",
    "        self.session = None\n",
    "\n",
    "    async def __aenter__(self):\n",
    "        self.session = aiohttp.ClientSession()\n",
    "        return self\n",
    "\n",
    "    async def __aexit__(self, *args):\n",
    "        await self.session.close()\n",
    "\n",
    "    async def expert_agent(self, chunk: str, chunk_id: int) -> Optional[Dict]:\n",
    "        \"\"\"Agente especialista com identificação de chunk\"\"\"\n",
    "        try:\n",
    "            prompt = f\"\"\"Analyze this text regarding: {self.question}\n",
    "            \n",
    "            Required JSON format:\n",
    "            {{\n",
    "                \"analysis\": {{\n",
    "                    \"key_findings\": [\"list\", \"of\", \"findings\"],\n",
    "                    \"missing_info\": [\"list\", \"of\", \"gaps\"]\n",
    "                }},\n",
    "                \"metadata\": {{\n",
    "                    \"chunk_id\": {chunk_id},\n",
    "                    \"relevance\": 0.0-1.0,\n",
    "                    \"needs_more_context\": true/false\n",
    "                }}\n",
    "            }}\n",
    "\n",
    "            Text: {chunk[:2000]}\"\"\"\n",
    "\n",
    "            async with self.session.post(\n",
    "                \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n",
    "                json={\n",
    "                    \"model\": \"qwen-qwq-32b\",\n",
    "                    \"messages\": [{\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You must respond in valid JSON format exactly as specified.\"\n",
    "                    }, {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }],\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"response_format\": {\"type\": \"json_object\"}\n",
    "                },\n",
    "                timeout=20\n",
    "            ) as response:\n",
    "                response.raise_for_status()\n",
    "                data = await response.json()\n",
    "                result = json.loads(data['choices'][0]['message']['content'])\n",
    "                \n",
    "                print(f\"Experto Agent Decision: {result}\")\n",
    "                \n",
    "                # Validate response structure\n",
    "                required_keys = {'analysis', 'metadata'}\n",
    "                if not all(key in result for key in required_keys):\n",
    "                    raise ValueError(\"Missing required keys in response\")\n",
    "                \n",
    "                self.processed_chunks.add(chunk_id)\n",
    "                if result['metadata']['relevance'] > 0.4:\n",
    "                    self.partial_answers.append(result)\n",
    "                return result\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON Error in chunk {chunk_id}: {str(e)}\")\n",
    "        except KeyError as e:\n",
    "            print(f\"Missing key in chunk {chunk_id} response: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk {chunk_id}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    async def central_agent(self) -> Dict:\n",
    "        \"\"\"Agente central que pode solicitar mais chunks\"\"\"\n",
    "        max_attempts = 3\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                context = \"\\n\".join(\n",
    "                    f\"Chunk {ans['metadata']['chunk_id']}:\\n\"\n",
    "                    f\"Findings: {ans['analysis']['key_findings']}\\n\"\n",
    "                    f\"Missing: {ans['analysis']['missing_info']}\"\n",
    "                    for ans in self.partial_answers\n",
    "                )\n",
    "\n",
    "                prompt = f\"\"\"Evaluate these analyses about: {self.question}\n",
    "                \n",
    "                Current Analysis:\n",
    "                {context}\n",
    "                \n",
    "                Required JSON response:\n",
    "                {{\n",
    "                    \"status\": \"complete\" or \"incomplete\",\n",
    "                    \"answer\": \"summary text\" or null,\n",
    "                    \"requested_chunks\": [list, of, ids] or null,\n",
    "                    \"confidence\": 0.0-1.0\n",
    "                }}\"\"\"\n",
    "\n",
    "                async with self.session.post(\n",
    "                    \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "                    headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n",
    "                    json={\n",
    "                        \"model\": \"qwen-qwq-32b\",\n",
    "                        \"messages\": [{\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": \"You must provide valid JSON. Double-check your output before returning.\"\n",
    "                        }, {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": prompt\n",
    "                        }],\n",
    "                        \"temperature\": 0.2,\n",
    "                        \"response_format\": {\"type\": \"json_object\"}\n",
    "                    },\n",
    "                    timeout=25\n",
    "                ) as response:\n",
    "                    response.raise_for_status()\n",
    "                    data = await response.json()\n",
    "                    decision = json.loads(data['choices'][0]['message']['content'])\n",
    "                    \n",
    "                    print(f\"Central Agent Decision: {decision}\")\n",
    "                    \n",
    "                    # Validate central agent response\n",
    "                    if not all(k in decision for k in [\"status\", \"answer\", \"requested_chunks\", \"confidence\"]):\n",
    "                        raise ValueError(\"Invalid central agent response format\")\n",
    "                    \n",
    "                    if decision[\"status\"] == \"complete\":\n",
    "                        return {\n",
    "                            \"status\": \"success\",\n",
    "                            \"answer\": decision[\"answer\"],\n",
    "                            \"confidence\": decision[\"confidence\"],\n",
    "                            \"used_chunks\": [ans['metadata']['chunk_id'] for ans in self.partial_answers]\n",
    "                        }\n",
    "                    \n",
    "                    # Process requested chunks if incomplete\n",
    "                    if decision[\"requested_chunks\"]:\n",
    "                        await self.process_additional_chunks(decision[\"requested_chunks\"])\n",
    "                        \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON Error (attempt {attempt + 1}): {str(e)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Central agent error (attempt {attempt + 1}): {str(e)}\")\n",
    "            \n",
    "        return {\"status\": \"error\", \"message\": \"Failed after maximum attempts\"}\n",
    "\n",
    "    async def process_additional_chunks(self, chunk_ids: List[int]):\n",
    "        \"\"\"Processa chunks adicionais solicitados pelo central agent\"\"\"\n",
    "        tasks = []\n",
    "        for chunk_id in chunk_ids:\n",
    "            if chunk_id not in self.processed_chunks and 0 <= chunk_id < len(self.all_chunks):\n",
    "                tasks.append(self.expert_agent(self.all_chunks[chunk_id], chunk_id))\n",
    "        \n",
    "        if tasks:\n",
    "            await asyncio.gather(*tasks)\n",
    "\n",
    "async def analyze_with_feedback(api_key: str, question: str, chunks: List[str]):\n",
    "    \"\"\"Pipeline com loop iterativo de análise\"\"\"\n",
    "    async with SmartAgentSystem(api_key, question, chunks) as system:\n",
    "        # Primeira rodada com 3 chunks iniciais\n",
    "        initial_batch = min(3, len(chunks))\n",
    "        initial_chunk_ids = list(range(initial_batch))\n",
    "        await system.process_additional_chunks(initial_chunk_ids)\n",
    "        \n",
    "        # Run central analysis\n",
    "        result = await system.central_agent()\n",
    "        \n",
    "        # If initial attempt failed but we have partial answers\n",
    "        if result[\"status\"] == \"error\" and system.partial_answers:\n",
    "            return {\n",
    "                \"status\": \"partial\",\n",
    "                \"answers\": system.partial_answers,\n",
    "                \"message\": \"Using partial results after central agent failure\"\n",
    "            }\n",
    "        return result\n",
    "\n",
    "# Exemplo de uso:\n",
    "async def main():\n",
    "    question = \"\"\"\n",
    "    \n",
    "    Analyze the author's journey through Veridia and Eldoria, detailing the methods they employ\n",
    "    to document their experiences, and discuss how their interactions with people\n",
    "    and places shape their understanding of these regions' unique identities.\n",
    "    \"\"\"\n",
    "    result = await analyze_with_feedback(GROQ_API_KEY, question, chunks)\n",
    "    \n",
    "    print(\"\\n=== Resultado Final ===\")\n",
    "    print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Executar no Jupyter:\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ee704a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb9035a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunks to Process: 2\n",
      "Parte de um Chunk:\n",
      "['2nd Day of Emberglow 1855 - Ar', '4th Day of Emberglow 1855 - Ex']\n",
      "All Chunks: [\"28th Day of Frostfall 1855 - Oakhaven's Delights\\nMy last day in Oakhaven was spent in the town square. I was lucky enough to witness a small festival celebrating the moonpetal harvest. The townspeople were adorned with moonpetal garlands, and the air was filled with music. I finally got to try the famous moonpetal tea. It has a delicate, sweet flavor with a slight floral aroma. I also learned that, beyond its use in tea, moonpetal is used to make a surprisingly potent liquor and that its leaves are used in traditional Oakhaven cooking. I purchased a small vial of moonpetal perfume to take with me, a reminder of this unique place.\"]\n",
      "Expert Agent Decision: {'analysis': {'key_findings': [\"The diary entry does not mention 'moonpetal' or any references to Oakhaven's cultural or economic practices related to it.\", 'The text focuses on coastal exploration, fishing boats, and natural geography, with no direct connection to flora or local customs.'], 'missing_info': ['No information about the use, significance, or prevalence of moonpetal in Oakhaven.', 'Lack of details about local culture, economy, or traditions tied to the flower.']}, 'metadata': {'chunk_id': 1, 'relevance': 0.2, 'needs_more_context': True}}\n",
      "Expert Agent Decision: {'analysis': {'key_findings': ['Moonpetal is used by Oakhaven residents in multiple applications, though specific uses are not detailed in the text.', \"The flower's scent is pervasive, suggesting it may be cultivated or harvested on a significant scale, possibly for trade, medicinal purposes, or local industry.\", \"The blend of old and new architecture implies a culture that values tradition while adapting to modernity, potentially reflecting moonpetal's role in both historical and contemporary practices.\", 'The prominence of moonpetal in a coastal town might indicate its utility in maritime activities (e.g., preserving goods, scent masking, or ritual use).'], 'missing_info': ['Exact uses of moonpetal (e.g., culinary, medicinal, decorative, or industrial).', 'Whether moonpetal cultivation or harvesting is a primary economic driver or a supplementary resource.', 'Cultural significance or symbolic meanings tied to moonpetal in local traditions.']}, 'metadata': {'chunk_id': 0, 'relevance': 0.7, 'needs_more_context': True}}\n",
      "Partial Answers: [{'analysis': {'key_findings': ['Moonpetal is used by Oakhaven residents in multiple applications, though specific uses are not detailed in the text.', \"The flower's scent is pervasive, suggesting it may be cultivated or harvested on a significant scale, possibly for trade, medicinal purposes, or local industry.\", \"The blend of old and new architecture implies a culture that values tradition while adapting to modernity, potentially reflecting moonpetal's role in both historical and contemporary practices.\", 'The prominence of moonpetal in a coastal town might indicate its utility in maritime activities (e.g., preserving goods, scent masking, or ritual use).'], 'missing_info': ['Exact uses of moonpetal (e.g., culinary, medicinal, decorative, or industrial).', 'Whether moonpetal cultivation or harvesting is a primary economic driver or a supplementary resource.', 'Cultural significance or symbolic meanings tied to moonpetal in local traditions.']}, 'metadata': {'chunk_id': 0, 'relevance': 0.7, 'needs_more_context': True}}]\n",
      "Central Agent Decision: {'status': 'incomplete', 'answer': 'Moonpetal is used in Oakhaven across multiple applications, though specifics remain unspecified. Its widespread cultivation suggests economic roles like trade, medicine, or industry, while its maritime context hints at uses like preservation or rituals. The town’s architectural blend implies cultural adaptability. However, exact uses, economic primacy, and symbolic meanings are unconfirmed.', 'requested_chunks': [0], 'confidence': 0.3}\n",
      "\n",
      "Chunks to Process: 1\n",
      "Parte de um Chunk:\n",
      "['28th Day of Frostfall 1855 - O']\n",
      "All Chunks: [\"28th Day of Frostfall 1855 - Oakhaven's Delights\\nMy last day in Oakhaven was spent in the town square. I was lucky enough to witness a small festival celebrating the moonpetal harvest. The townspeople were adorned with moonpetal garlands, and the air was filled with music. I finally got to try the famous moonpetal tea. It has a delicate, sweet flavor with a slight floral aroma. I also learned that, beyond its use in tea, moonpetal is used to make a surprisingly potent liquor and that its leaves are used in traditional Oakhaven cooking. I purchased a small vial of moonpetal perfume to take with me, a reminder of this unique place.\"]\n",
      "Expert Agent Decision: {'analysis': {'key_findings': ['Moonpetal is used in tea, liquor, cooking, and perfume, indicating its versatility as a resource.', 'The festival celebrating the moonpetal harvest highlights its cultural significance as a symbol of communal celebration and tradition.', \"The prevalence of moonpetal in both daily life (food, drink) and luxury items (perfume) suggests it is a cornerstone of Oakhaven's economy and social identity.\", 'The production of potent liquor and perfume implies some level of specialized craftsmanship or trade, possibly contributing to local economic activity.'], 'missing_info': ['Details about how moonpetal is cultivated or harvested (e.g., labor practices, seasonal cycles).', 'Whether moonpetal is exported or traded beyond Oakhaven, or if it is solely for local use.', 'Cultural beliefs or rituals tied to moonpetal beyond the festival (e.g., spiritual significance, historical origins).', \"Economic data, such as moonpetal's role in trade revenue or its impact on Oakhaven's prosperity.\"]}, 'metadata': {'chunk_id': 0, 'relevance': 0.9, 'needs_more_context': True}}\n",
      "Partial Answers: [{'analysis': {'key_findings': ['Moonpetal is used by Oakhaven residents in multiple applications, though specific uses are not detailed in the text.', \"The flower's scent is pervasive, suggesting it may be cultivated or harvested on a significant scale, possibly for trade, medicinal purposes, or local industry.\", \"The blend of old and new architecture implies a culture that values tradition while adapting to modernity, potentially reflecting moonpetal's role in both historical and contemporary practices.\", 'The prominence of moonpetal in a coastal town might indicate its utility in maritime activities (e.g., preserving goods, scent masking, or ritual use).'], 'missing_info': ['Exact uses of moonpetal (e.g., culinary, medicinal, decorative, or industrial).', 'Whether moonpetal cultivation or harvesting is a primary economic driver or a supplementary resource.', 'Cultural significance or symbolic meanings tied to moonpetal in local traditions.']}, 'metadata': {'chunk_id': 0, 'relevance': 0.7, 'needs_more_context': True}}, {'analysis': {'key_findings': ['Moonpetal is used in tea, liquor, cooking, and perfume, indicating its versatility as a resource.', 'The festival celebrating the moonpetal harvest highlights its cultural significance as a symbol of communal celebration and tradition.', \"The prevalence of moonpetal in both daily life (food, drink) and luxury items (perfume) suggests it is a cornerstone of Oakhaven's economy and social identity.\", 'The production of potent liquor and perfume implies some level of specialized craftsmanship or trade, possibly contributing to local economic activity.'], 'missing_info': ['Details about how moonpetal is cultivated or harvested (e.g., labor practices, seasonal cycles).', 'Whether moonpetal is exported or traded beyond Oakhaven, or if it is solely for local use.', 'Cultural beliefs or rituals tied to moonpetal beyond the festival (e.g., spiritual significance, historical origins).', \"Economic data, such as moonpetal's role in trade revenue or its impact on Oakhaven's prosperity.\"]}, 'metadata': {'chunk_id': 0, 'relevance': 0.9, 'needs_more_context': True}}]\n",
      "Central Agent Decision: {'status': 'incomplete', 'answer': 'Moonpetal is used in Oakhaven for culinary purposes (tea, cooking, liquor), perfumes, and cultural festivals, indicating it is central to both daily life and economic activity. Its prevalence suggests a culture valuing tradition (via festivals and historical practices) alongside economic adaptation through specialized crafts (e.g., perfume-making). The flower may also support trade or maritime uses given the coastal setting, though specifics about cultivation methods, export, and deeper cultural symbolism remain unclear.', 'requested_chunks': [0, 1], 'confidence': 0.7}\n",
      "Result: {'status': 'success', 'answer': 'Moonpetal is used in Oakhaven for culinary purposes (tea, cooking, liquor), perfumes, and cultural festivals, indicating it is central to both daily life and economic activity. Its prevalence suggests a culture valuing tradition (via festivals and historical practices) alongside economic adaptation through specialized crafts (e.g., perfume-making). The flower may also support trade or maritime uses given the coastal setting, though specifics about cultivation methods, export, and deeper cultural symbolism remain unclear.', 'confidence': 0.7, 'used_chunks': [0, 0]}\n",
      "\n",
      "=== Resultado Final ===\n",
      "{\n",
      "  \"status\": \"success\",\n",
      "  \"answer\": \"Moonpetal is used in Oakhaven for culinary purposes (tea, cooking, liquor), perfumes, and cultural festivals, indicating it is central to both daily life and economic activity. Its prevalence suggests a culture valuing tradition (via festivals and historical practices) alongside economic adaptation through specialized crafts (e.g., perfume-making). The flower may also support trade or maritime uses given the coastal setting, though specifics about cultivation methods, export, and deeper cultural symbolism remain unclear.\",\n",
      "  \"used_chunks\": [\n",
      "    0,\n",
      "    1\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import json\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "class SmartAgentSystem:\n",
    "    def __init__(self, api_key: str, question: str, all_chunks: List[str]):\n",
    "        self.api_key = api_key\n",
    "        self.question = question\n",
    "        self.all_chunks = all_chunks\n",
    "        self.processed_chunks = set()\n",
    "        self.partial_answers = []\n",
    "        self.session = None\n",
    "\n",
    "    async def __aenter__(self):\n",
    "        self.session = aiohttp.ClientSession()\n",
    "        return self\n",
    "\n",
    "    async def __aexit__(self, *args):\n",
    "        await self.session.close()\n",
    "\n",
    "    async def expert_agent(self, chunk: str, chunk_id: int) -> Optional[Dict]:\n",
    "        \"\"\"Agente especialista com identificação de chunk\"\"\"\n",
    "        try:\n",
    "            prompt = f\"\"\"Analyze this text regarding: {self.question}\n",
    "            \n",
    "            Required JSON format:\n",
    "            {{\n",
    "                \"analysis\": {{\n",
    "                    \"key_findings\": [\"list\", \"of\", \"findings\"],\n",
    "                    \"missing_info\": [\"list\", \"of\", \"gaps\"]\n",
    "                }},\n",
    "                \"metadata\": {{\n",
    "                    \"chunk_id\": {chunk_id},\n",
    "                    \"relevance\": 0.0-1.0,\n",
    "                    \"needs_more_context\": true/false\n",
    "                }}\n",
    "            }}\n",
    "\n",
    "            Text: {chunk}\"\"\"\n",
    "\n",
    "            async with self.session.post(\n",
    "                \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n",
    "                json={\n",
    "                    \"model\": \"qwen-qwq-32b\",\n",
    "                    \"messages\": [{\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You must respond in valid JSON format exactly as specified.\"\n",
    "                    }, {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }],\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"response_format\": {\"type\": \"json_object\"}\n",
    "                },\n",
    "                timeout=20\n",
    "            ) as response:\n",
    "                response.raise_for_status()\n",
    "                data = await response.json()\n",
    "                result = json.loads(data['choices'][0]['message']['content'])\n",
    "                \n",
    "                print(f\"Expert Agent Decision: {result}\")\n",
    "                \n",
    "                # Validate response structure\n",
    "                required_keys = {'analysis', 'metadata'}\n",
    "                if not all(key in result for key in required_keys):\n",
    "                    raise ValueError(\"Missing required keys in response\")\n",
    "                \n",
    "                self.processed_chunks.add(chunk_id)\n",
    "                if result['metadata']['relevance'] > 0.4:\n",
    "                    self.partial_answers.append(result)\n",
    "                return result\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON Error in chunk {chunk_id}: {str(e)}\")\n",
    "        except KeyError as e:\n",
    "            print(f\"Missing key in chunk {chunk_id} response: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk {chunk_id}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    async def central_agent(self) -> Dict:\n",
    "        \"\"\"Agente central que pode solicitar mais chunks\"\"\"\n",
    "        max_attempts = 1\n",
    "        print(f\"Partial Answers: {self.partial_answers}\")\n",
    "    \n",
    "        try:\n",
    "            context = \"\\n\".join(\n",
    "                f\"Chunk {ans['metadata']['chunk_id']}:\\n\"\n",
    "                f\"Findings: {ans['analysis']['key_findings']}\\n\"\n",
    "                f\"Missing: {ans['analysis']['missing_info']}\"\n",
    "                for ans in self.partial_answers\n",
    "            )\n",
    "            # context = \"\\n\".join(\n",
    "            #     f\"Chunk {ans['metadata']['chunk_id']}:\\n\"\n",
    "            #     f\"Findings: {ans['analysis']['key_findings']}\"\n",
    "                \n",
    "            #     for ans in self.partial_answers\n",
    "            # )\n",
    "\n",
    "            prompt = f\"\"\"Evaluate these analyses about: {self.question}\n",
    "            \n",
    "            Current Analysis:\n",
    "            {context}\n",
    "            \n",
    "            Required JSON response:\n",
    "            {{\n",
    "                \"status\": \"complete\" or \"incomplete\",\n",
    "                \"answer\": \"summary text\" or null,\n",
    "                \"requested_chunks\": [list, of, ids] or null,\n",
    "                \"confidence\": 0.0-1.0\n",
    "            }}\"\"\"\n",
    "\n",
    "            async with self.session.post(\n",
    "                \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n",
    "                json={\n",
    "                    \"model\": \"qwen-qwq-32b\",\n",
    "                    \"messages\": [{\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You must provide valid JSON. Double-check your output before returning.\"\n",
    "                    }, {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }],\n",
    "                    \"temperature\": 0.2,\n",
    "                    \"response_format\": {\"type\": \"json_object\"}\n",
    "                },\n",
    "                timeout=25\n",
    "            ) as response:\n",
    "                response.raise_for_status()\n",
    "                data = await response.json()\n",
    "                decision = json.loads(data['choices'][0]['message']['content'])\n",
    "                \n",
    "                print(f\"Central Agent Decision: {decision}\")\n",
    "                \n",
    "                # Validate central agent response\n",
    "                if not all(k in decision for k in [\"status\", \"answer\", \"requested_chunks\", \"confidence\"]):\n",
    "                    raise ValueError(\"Invalid central agent response format\")\n",
    "                \n",
    "                if decision[\"status\"] == \"complete\" or decision['confidence'] > 0.6:\n",
    "                    return {\n",
    "                        \"status\": \"success\",\n",
    "                        \"answer\": decision[\"answer\"],\n",
    "                        \"confidence\": decision[\"confidence\"],\n",
    "                        \"used_chunks\": [ans['metadata']['chunk_id'] for ans in self.partial_answers]\n",
    "                    }\n",
    "                \n",
    "                else:\n",
    "                    await self.process_additional_chunks(decision[\"requested_chunks\"])\n",
    "                    \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON Error: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Central agent error: {str(e)}\")\n",
    "        \n",
    "\n",
    "    async def process_additional_chunks(self, chunk_ids: List[int], first=False):\n",
    "        \"\"\"Processa chunks adicionais de forma simples e eficiente\"\"\"\n",
    "        # Filtra apenas chunks não processados e válidos\n",
    "        \n",
    "        chunks_to_process = self.all_chunks[:2]\n",
    "        \n",
    "        # Processa todos os chunks válidos de uma vez\n",
    "        if chunks_to_process:\n",
    "            print(f\"\\nChunks to Process: {len(chunks_to_process)}\")\n",
    "            print(\"Parte de um Chunk:\")\n",
    "            _ = [chunk[:30] for chunk_id, chunk in enumerate(chunks_to_process)]\n",
    "            print(_[:30])\n",
    "            tasks = [\n",
    "                self.expert_agent(chunk, chunk_id) \n",
    "                for chunk_id, chunk in enumerate(chunks_to_process)\n",
    "            ]\n",
    "            self.all_chunks = self.all_chunks[-1:]\n",
    "            print(f\"All Chunks: {self.all_chunks[:50]}\")\n",
    "            await asyncio.gather(*tasks)\n",
    "\n",
    "async def analyze_with_feedback(api_key: str, question: str, chunks: List[str]):\n",
    "    \"\"\"Versão simplificada do pipeline de análise\"\"\"\n",
    "    async with SmartAgentSystem(api_key, question, chunks) as system:\n",
    "        # Processa os 3 primeiros chunks inicialmente\n",
    "        await system.process_additional_chunks([0, 1, 2], first=True)\n",
    "        \n",
    "        # Obtém a decisão do agente central\n",
    "        \n",
    "        result = await system.central_agent()\n",
    "        \n",
    "        while not result:\n",
    "            result = await system.central_agent()\n",
    "        \n",
    "        print(f\"Result: {result}\")\n",
    "        \n",
    "        # Retorna o resultado seja qual for o status\n",
    "        return {\n",
    "            \"status\": result[\"status\"],\n",
    "            \"answer\": result.get(\"answer\"),\n",
    "            \"used_chunks\": list(system.processed_chunks)\n",
    "        }\n",
    "        \n",
    "            \n",
    "\n",
    "# Exemplo de uso:\n",
    "async def main():\n",
    "    question = \"\"\"\n",
    "    Based on the diary entries, describe the uses of moonpetal by the people of Oakhaven and what the prevalence of this flower suggests about the local culture and economy.\n",
    "    \"\"\"\n",
    "    result = await analyze_with_feedback(GROQ_API_KEY, question, chunks)\n",
    "    \n",
    "    print(\"\\n=== Resultado Final ===\")\n",
    "    print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Executar no Jupyter:\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a1110fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "434b9804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('28th Day of Frostfall 1855 - A Celebration of Craft\\n'\n",
      " 'The soft luminescence of dawn cast a gentle glow over the countryside as I '\n",
      " \"departed for the Veridian Artisans' Fair. [cite: 612, 613] This renowned \"\n",
      " 'event thrives annually, lauded for its display of exceptional craftsmanship, '\n",
      " 'and I have long anticipated witnessing the skill and creativity of Veridia’s '\n",
      " 'artisans firsthand. [cite: 613, 614]\\n'\n",
      " 'As I strolled among the bustling stalls, each exhibit boasted a distinct '\n",
      " 'piece of culture—a tapestry woven with threads of history, or a sculpture '\n",
      " 'hewn from the heart of the land itself. [cite: 614, 615] An elder craftsman, '\n",
      " 'his hands worn yet graceful, walked me through his collection of glistening '\n",
      " 'glassware. [cite: 615, 616, 617] He spoke with pride of his lineage, each '\n",
      " 'piece carrying a story not just of his making, but of all the hands that '\n",
      " 'came before him. [cite: 616, 617] This passing of art through generations '\n",
      " 'mirrors the lasting beauty of the pristine beaches and marine biodiversity '\n",
      " 'along the Veridian Coast, a natural artistry I hope to explore soon. [cite: '\n",
      " '617, 618]\\n'\n",
      " \"The Veridian Artisans' Fair is known not only for its crafts but also for \"\n",
      " 'showcasing new culinary trends. [cite: 618, 619, 620] This year, there was a '\n",
      " 'noticeable emphasis on dishes incorporating skyroot, an herb from the '\n",
      " 'Gerlian Mountains, celebrated for its unique flavor and healthful '\n",
      " 'properties. [cite: 618, 619, 620]\\n'\n",
      " 'Later, in the heart of the fair, a troupe of musicians played a lively tune, '\n",
      " 'their instruments as varied as the region itself. [cite: 618, 619, 620] '\n",
      " 'These melodies seemed to capture the essence of Veridian life, remembrances '\n",
      " 'of both tradition and innovation. [cite: 618, 619, 620] It seems fitting '\n",
      " 'that such a vibrant display is found here, in a country that places emphasis '\n",
      " 'on sustainable technology and green initiatives to secure a harmonious '\n",
      " 'future. [cite: 618, 619, 620]')\n"
     ]
    }
   ],
   "source": [
    "pprint(chunks[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
